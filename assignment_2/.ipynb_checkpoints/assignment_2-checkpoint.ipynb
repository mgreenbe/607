{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Spam detection\n",
    "\n",
    "### Due Wednesday, March 20; submit through D2L dropbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Write a python function that returns\n",
    "    1. the frequency of a given character,\n",
    "    2. the frequency of a given word (maximal consecutive sequence of letters, case insensitive),\n",
    "    3. a list of all maximal sequences of consecutive capital letters,\n",
    "\n",
    "    in a string.\n",
    "\n",
    "2.  For each message in the dataset `sms_spam.csv`, compute:\n",
    "    1. the frequency of the each of the words in the list `words` defined below,\n",
    "    2. the frequency of the each of the characters in the list `chars` defined below,\n",
    "    3. the average run length of a maximal sequence of capital letters,\n",
    "    4. the longest run length of a maximal sequence of capital letters,\n",
    "    5. the sum of the run lengths of the maximal sequences of capital letters.\n",
    "    \n",
    "    **More precisely:**\n",
    "    \n",
    "    - One can interpret *word* in a numbe of ways.\n",
    "    If we interpret *word* it as a string of consecutive letters, the sentence,\n",
    "    \"The reporter filed a report about reportables.\" contains three occurences of the word *report*.\n",
    "    We could also interpred *word* as a string of consecutive letters, neither preceded nor followed by a letter,\n",
    "    then that sentence would contain only one occurence of the work *report*.\n",
    "    Choose whichever one of these interpretations your prefer. If you think of a better interpretation, feel free to use that.\n",
    "    \n",
    "    - The simplest interpretation of maximal sequence of capital letters is a sequence of capital letters\n",
    "    neither preceded nor followed by a capital letter.\n",
    "    For example, in the string \"abcDEFGhiJKL345 MNO PQR\", \"DEFG\", \"JKL\", \"MNO\" and \"PQR\"\n",
    "    are maximal sequences of capital letters while \"DEF\" \"KL\" and \"MNO PQR\" aren't.\n",
    "    (The first two aren't maximal and the third doesn't consist entirely of capital letters.)\n",
    "    This isn't the only interpretation. In the string \"He shouted, 'STOP SHOUTING AT ME!'\", one could argue that \"STOP SHOUTING AT ME\"\n",
    "    should count as a single (maximal) sequence of capital letters. If you prefer such an interpretation, feel free to use it.\n",
    "    \n",
    "    - These details aren't really the point. We're just trying to extract features for analysis. Any reasonable approach is fine.\n",
    "    \n",
    "3.  Arrange the results in a dataframe. The frequencies computed in 1. and 2. should go in columns named\n",
    "    `freq_<word>` and `freq_<char>`, respectively. The run lengths in 3., 4., and 5. should go in columns named\n",
    "    `capital_run_length_average`, `capital_run_length_longest`, and `capital_run_length_total`, respectively.\n",
    "    The last column in your dataframe should be the target, 1 if the target is spam and 0 if it isn't.\n",
    "    Save your dataset as a `.csv` file called `sms_spam_features.csv`.\n",
    "\n",
    "\n",
    "4.  Based on these 57 features, use a decision tree to train a spam-detecting classifier:\n",
    "    - Separate you data into training and training and testing sets.\n",
    "    - Train a decision tree on the training set.\n",
    "    - Compute the accuracy on the test set.\n",
    "    - Repeat this many, times and, for each iteration, note the testing accuracy and the feature importances.\n",
    "    - Approximate the mean and standard deviation of your testing accuracy estimate.\n",
    "    - Make a bar chart of average feature importances, sorted.\n",
    "\n",
    "5.  Repeat 4. using random forests.\n",
    "\n",
    "6.  Repeat 2. through 4. for the dataset `spam_or_not_spam.csv`.\n",
    "\n",
    "8.  Comment on similarities/differences you notice between datasets (include our analysis of `spambase.csv`), classification methods, etc.\n",
    "\n",
    "7.  **Optional:** Construct spam detectors using other classifiers you've learned about, and compare their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet', 'order', 'mail', 'receive', 'will', 'people',\n",
    "         'report', 'addresses', 'free', 'business', 'email', 'you', 'credit', 'your', 'font', '000', 'money', 'hp', 'hpl', \n",
    "         'george', '650', 'lab', 'labs', 'telnet', '857', 'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct',\n",
    "         'cs', 'meeting', 'original', 'project', 're', 'edu', 'table', 'conference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [';', '(', '[', '!', '$', '#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
